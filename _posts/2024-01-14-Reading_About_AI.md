---
title: 'Reading about AI'
date: 2024-01-14
tags:
  - AI
  - reading
---

### What AI can give to scientists. What scientists want from AI 

GPT-4 more than GPT-3 can create human-like texts. Compared to the previous versions, the capability of interacting with images, graphs and generate codes are highly improved.
Furthermore GPT-4 has access to scientific papers, and can be trained with additional knowledge. This is the reason why it can be continuously improved, and most likely will be. However as a model that predicts the-next-word-in-a-sentence, it's still likely to report fake facts, called hallucinations. Scientists paid from OpenAI have tried to trigger wrong or dangerous answers, but the algorithm is strongly disencouraged to produce such an output. 

The model tries to have the higher level of alignment. As alignment is intended a model that follows human ethics. However it still seems more impressive at the first use rather then after spending some times with - said Sam Altman.

---
References
- [GPT-4 is here: what scientists think](https://www.nature.com/articles/d41586-023-00816-5) (Nature)
- [Holes in Europe's AI act and researchers can help to fill them](https://www.nature.com/articles/d41586-024-00029-4) (Nature)
- [How AI experts are using GPT4](https://www.technologyreview.com/2023/03/21/1070102/how-ai-experts-are-using-gpt-4/) (MIT - technology review)
- [OpenAI about hallucinations and other GPT-4 Limitations and dangers](https://cdn.openai.com/papers/gpt-4-system-card.pdf?mc_cid=47c1f3eb5f&mc_eid=51768751d5) (OpenAI)
- [What the new GPT4 Ai can do](https://www.scientificamerican.com/article/what-the-new-gpt-4-ai-can-do/) (Scientific American)
